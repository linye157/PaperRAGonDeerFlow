{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4087167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Ollama æœ¬åœ°æ¨¡å‹æµ‹è¯•\n",
      "============================================================\n",
      "\n",
      "1. ğŸš€ æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€...\n",
      "âœ… OllamaæœåŠ¡è¿è¡Œæ­£å¸¸\n",
      "   å¯ç”¨æ¨¡å‹: qwen3:0.6b, dengcao/bce-reranker-base_v1:latest, deepseek-r1:8b, llama3.1:latest, gemma3:12b, qwen3:14b, bge-m3:latest, nomic-embed-text:latest, deepseek-r1:14b\n",
      "\n",
      "2. ğŸ”Œ æµ‹è¯•OpenAIå…¼å®¹API...\n",
      "\n",
      "ğŸ” æµ‹è¯•OpenAIå…¼å®¹ç«¯ç‚¹: http://localhost:11434/v1\n",
      "âœ… OpenAIå…¼å®¹APIå¯ç”¨\n",
      "   å…¼å®¹ç«¯ç‚¹æ£€æµ‹åˆ°æ¨¡å‹æ•°é‡: 9\n",
      "   âœ… ç›®æ ‡æ¨¡å‹ 'qwen3:0.6b' å¯ç”¨\n",
      "\n",
      "3. ğŸ’¬ æµ‹è¯•ç®€å•å¯¹è¯...\n",
      "\n",
      "ğŸ’¬ æµ‹è¯•èŠå¤©è¡¥å…¨ (æ¨¡å‹: qwen3:0.6b)\n",
      "   å°è¯• 1/3...\n",
      "âœ… è¯·æ±‚æˆåŠŸ! è€—æ—¶: 1.56ç§’\n",
      "\n",
      "ğŸ“ æ¨¡å‹å›å¤:\n",
      "----------------------------------------\n",
      "<think>\n",
      "å¥½çš„ï¼Œç”¨æˆ·è®©æˆ‘ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ç¡®å®šç”¨æˆ·çš„éœ€æ±‚æ˜¯ä»€ä¹ˆã€‚å¯èƒ½ä»–æƒ³äº†è§£æˆ‘çš„åŸºæœ¬æƒ…å†µï¼Œæˆ–è€…æƒ³è¿›è¡ŒæŸç§å¯¹è¯ï¼Œæ¯”å¦‚è¯¢é—®æˆ‘çš„å…´è¶£ã€èƒ½åŠ›ï¼Œç”šè‡³æƒ³è¿›è¡ŒæŸç§äº’åŠ¨ã€‚æˆ‘éœ€è¦æ ¹æ®è¿™äº›å¯èƒ½æ€§æ¥ç»„ç»‡å›ç­”ã€‚\n",
      "\n",
      "ç”¨æˆ·å¯èƒ½æ²¡æœ‰æ˜ç¡®è¯´ï¼Œä½†ä½œä¸ºAIï¼Œæˆ‘éœ€è¦ä¿æŒå‹å¥½å’Œä¸“ä¸šçš„å½¢è±¡ã€‚è¦é¿å…è¿‡äºå†—é•¿ï¼Œä½†åˆè¦æ¶µç›–å…³é”®ä¿¡æ¯ã€‚å¯èƒ½éœ€è¦åŒ…æ‹¬æˆ‘çš„ä¸»è¦åŠŸèƒ½ã€åº”ç”¨åœºæ™¯ã€ä»·å€¼è§‚ï¼Œä»¥åŠå¦‚ä½•å¸®åŠ©ç”¨æˆ·ã€‚\n",
      "\n",
      "å¦å¤–ï¼Œç”¨æˆ·å¯èƒ½å¸Œæœ›å›ç­”ä¸­åŒ…å«ä¸€äº›äº’åŠ¨å…ƒç´ ï¼Œæ¯”å¦‚è¯¢é—®é—®é¢˜æˆ–è€…æä¾›å¸®åŠ©ã€‚è¿™æ—¶å€™å¯ä»¥ä¸»åŠ¨è¯¢é—®ï¼Œæ¯”å¦‚â€œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿâ€ã€‚è¿™ä¸ä»…æ˜¾ç¤ºäº†å¼€æ”¾çš„æ€åº¦ï¼Œä¹Ÿèƒ½ä¿ƒè¿›è¿›ä¸€æ­¥çš„äº¤æµã€‚\n",
      "\n",
      "éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¿æŒå›ç­”çš„\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“Š Tokenä½¿ç”¨:\n",
      "   è¾“å…¥token: 12\n",
      "   è¾“å‡ºtoken: 150\n",
      "   æ€»token: 162\n",
      "\n",
      "4. ğŸ§® æµ‹è¯•æ¨ç†èƒ½åŠ›...\n",
      "\n",
      "ğŸ’¬ æµ‹è¯•èŠå¤©è¡¥å…¨ (æ¨¡å‹: qwen3:0.6b)\n",
      "   å°è¯• 1/3...\n",
      "âœ… è¯·æ±‚æˆåŠŸ! è€—æ—¶: 0.40ç§’\n",
      "\n",
      "ğŸ“ æ¨¡å‹å›å¤:\n",
      "----------------------------------------\n",
      "<think>\n",
      "å¥½çš„ï¼Œæˆ‘ç°åœ¨è¦è§£å†³è¿™ä¸ªé—®é¢˜ï¼šå¦‚æœæˆ‘æœ‰3ä¸ªè‹¹æœï¼Œåƒæ‰1ä¸ªï¼Œåˆä¹°äº†5ä¸ªï¼Œç°åœ¨æœ‰å¤šå°‘ä¸ªè‹¹æœï¼Ÿè®©æˆ‘ä»”ç»†æƒ³æƒ³çœ‹ã€‚\n",
      "\n",
      "é¦–å…ˆï¼Œæˆ‘åº”è¯¥å…ˆç†æ¸…æ¥šè¿™ä¸ªè¿‡ç¨‹ã€‚åˆå§‹çš„æ—¶å€™ï¼Œæˆ‘æœ‰3ä¸ªè‹¹æœã€‚ç„¶åï¼Œé¢˜ç›®è¯´â€œåƒæ‰1ä¸ªâ€ï¼Œæ‰€ä»¥è¿™é‡Œéœ€è¦æ³¨æ„ï¼Œåƒæ‰è‹¹æœæ˜¯å¦æ„å‘³ç€ä»è‹¹æœä¸­å»æ‰ï¼Œè¿˜æ˜¯è¯´æˆ‘å‡å°‘äº†è‹¹æœçš„æ•°é‡ï¼Ÿé€šå¸¸æ¥è¯´ï¼Œåƒæ‰ä¸œè¥¿åº”è¯¥æ˜¯æŒ‡ä»è‹¹æœä¸­å»æ‰ï¼Œæ‰€ä»¥\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“Š Tokenä½¿ç”¨:\n",
      "   è¾“å…¥token: 30\n",
      "   è¾“å‡ºtoken: 100\n",
      "   æ€»token: 130\n",
      "\n",
      "5. ğŸŒŠ æµ‹è¯•æµå¼è¾“å‡º...\n",
      "\n",
      "ğŸŒŠ æµ‹è¯•æµå¼è¾“å‡º\n",
      "   å¼€å§‹æ¥æ”¶æµå¼å“åº”...\n",
      "----------------------------------------\n",
      "<think>\n",
      "å¥½çš„ï¼Œç”¨æˆ·è®©æˆ‘ç”¨ä¸‰å¥è¯æè¿°å¤å¤©çš„ç¾å¥½ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ç¡®å®šç”¨æˆ·çš„éœ€æ±‚æ˜¯ä»€ä¹ˆã€‚ä»–ä»¬å¯èƒ½æ˜¯åœ¨å¯»æ‰¾ä¸€äº›ç”ŸåŠ¨çš„å¤æ—¥æè¿°ï¼Œç”¨äºå†™ä½œã€æ¼”è®²æˆ–è€…åªæ˜¯æƒ³è¡¨è¾¾å¯¹å¤å¤©çš„æ¬£èµã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘å¾—è€ƒè™‘å¦‚ä½•ç”¨ä¸‰å¥è¯æ¥æ¶µç›–ä¸åŒçš„æ–¹é¢ï¼Œæ¯”å¦‚è‡ªç„¶æ™¯è§‚ã€æ´»åŠ¨å’Œæ„Ÿå—ã€‚\n",
      "\n",
      "ç¬¬ä¸€å¥ï¼Œå¯èƒ½éœ€è¦æç»˜è‡ªç„¶çš„ç¾ä¸½ï¼Œæ¯”å¦‚é˜³å…‰ã€\n",
      "----------------------------------------\n",
      "âœ… æµå¼è¾“å‡ºå®Œæˆï¼Œæ€»é•¿åº¦: 142 å­—ç¬¦\n",
      "\n",
      "6. ğŸ“ æµ‹è¯•æ–‡æœ¬ç”Ÿæˆæ¥å£...\n",
      "\n",
      "ğŸ“ æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ\n",
      "âœ… æ–‡æœ¬ç”ŸæˆæˆåŠŸ:\n",
      "----------------------------------------\n",
      "äººå·¥æ™ºèƒ½çš„æœªæ¥æ˜¯<think>\n",
      "å—¯ï¼Œç”¨æˆ·é—®çš„æ˜¯â€œäººå·¥æ™ºèƒ½çš„æœªæ¥æ˜¯ï¼Ÿâ€ï¼Œæˆ‘éœ€è¦å…ˆç†è§£ä»–ä»¬çš„éœ€æ±‚ã€‚å¯èƒ½ä»–ä»¬æƒ³äº†è§£AIçš„æœªæ¥å‘å±•ï¼Œæˆ–è€…å¯¹AIçš„ä¼¦ç†ã€ç¤¾ä¼šå½±å“ç­‰æ„Ÿå…´è¶£ã€‚ç”¨æˆ·å¯èƒ½æœ‰å¤šç§ç–‘é—®ï¼Œéœ€è¦æˆ‘ä»¥å¼€æ”¾\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ç¡…åŸºæµåŠ¨APIæµ‹è¯•\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "\n",
    "class OllamaTester:\n",
    "    def __init__(self, config):\n",
    "        self.base_url = config.get(\"base_url\", \"http://localhost:11434/v1\")\n",
    "        self.model = config.get(\"model\", \"llama3.1:latest\").strip()\n",
    "        self.api_key = config.get(\"api_key\", \"ollama\")\n",
    "        self.verify_ssl = config.get(\"verify_ssl\", False)\n",
    "        self.max_retries = config.get(\"max_retries\", 3)\n",
    "        \n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        if self.api_key:\n",
    "            self.headers[\"Authorization\"] = f\"Bearer {self.api_key}\"\n",
    "    \n",
    "    def check_ollama_status(self):\n",
    "        \"\"\"æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œ\"\"\"\n",
    "        try:\n",
    "            # å°è¯•è®¿é—®OllamaåŸç”ŸAPIç«¯ç‚¹\n",
    "            response = requests.get(\n",
    "                \"http://localhost:11434/api/tags\",\n",
    "                timeout=5,\n",
    "                verify=self.verify_ssl\n",
    "            )\n",
    "            if response.status_code == 200:\n",
    "                models = response.json().get(\"models\", [])\n",
    "                print(\"âœ… OllamaæœåŠ¡è¿è¡Œæ­£å¸¸\")\n",
    "                print(f\"   å¯ç”¨æ¨¡å‹: {', '.join([m.get('name', '') for m in models])}\")\n",
    "                return True\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡: {str(e)}\")\n",
    "            print(\"   è¯·ç¡®ä¿Ollamaå·²å¯åŠ¨: ollama serve\")\n",
    "            return False\n",
    "    \n",
    "    def test_openai_compatible_api(self):\n",
    "        \"\"\"æµ‹è¯•OpenAIå…¼å®¹API\"\"\"\n",
    "        print(f\"\\nğŸ” æµ‹è¯•OpenAIå…¼å®¹ç«¯ç‚¹: {self.base_url}\")\n",
    "        \n",
    "        # æµ‹è¯•åˆ—å‡ºæ¨¡å‹\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                f\"{self.base_url}/models\",\n",
    "                headers=self.headers,\n",
    "                timeout=10,\n",
    "                verify=self.verify_ssl\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                models = response.json().get(\"data\", [])\n",
    "                print(f\"âœ… OpenAIå…¼å®¹APIå¯ç”¨\")\n",
    "                print(f\"   å…¼å®¹ç«¯ç‚¹æ£€æµ‹åˆ°æ¨¡å‹æ•°é‡: {len(models)}\")\n",
    "                \n",
    "                # æ£€æŸ¥ç›®æ ‡æ¨¡å‹æ˜¯å¦å¯ç”¨\n",
    "                target_model_found = any(\n",
    "                    self.model in model.get(\"id\", \"\") for model in models\n",
    "                )\n",
    "                if target_model_found:\n",
    "                    print(f\"   âœ… ç›®æ ‡æ¨¡å‹ '{self.model}' å¯ç”¨\")\n",
    "                else:\n",
    "                    print(f\"   âš ï¸  ç›®æ ‡æ¨¡å‹ '{self.model}' æœªåœ¨åˆ—è¡¨ä¸­ï¼Œå¯èƒ½åç§°ä¸åŒ¹é…\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"âŒ OpenAIå…¼å®¹APIè¿”å›é”™è¯¯: {response.status_code}\")\n",
    "                print(f\"   å“åº”: {response.text}\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ OpenAIå…¼å®¹APIè¿æ¥å¤±è´¥: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def test_chat_completion(self, prompt=\"Hello, how are you?\", max_tokens=100):\n",
    "        \"\"\"æµ‹è¯•èŠå¤©è¡¥å…¨åŠŸèƒ½\"\"\"\n",
    "        print(f\"\\nğŸ’¬ æµ‹è¯•èŠå¤©è¡¥å…¨ (æ¨¡å‹: {self.model})\")\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        \n",
    "        data = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": messages,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0.7,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                print(f\"   å°è¯• {attempt + 1}/{self.max_retries}...\")\n",
    "                start_time = time.time()\n",
    "                \n",
    "                response = requests.post(\n",
    "                    f\"{self.base_url}/chat/completions\",\n",
    "                    headers=self.headers,\n",
    "                    json=data,\n",
    "                    timeout=60,\n",
    "                    verify=self.verify_ssl\n",
    "                )\n",
    "                \n",
    "                elapsed_time = time.time() - start_time\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    result = response.json()\n",
    "                    print(f\"âœ… è¯·æ±‚æˆåŠŸ! è€—æ—¶: {elapsed_time:.2f}ç§’\")\n",
    "                    \n",
    "                    # æå–å›å¤å†…å®¹\n",
    "                    if \"choices\" in result and len(result[\"choices\"]) > 0:\n",
    "                        reply = result[\"choices\"][0].get(\"message\", {}).get(\"content\", \"\")\n",
    "                        print(f\"\\nğŸ“ æ¨¡å‹å›å¤:\")\n",
    "                        print(\"-\" * 40)\n",
    "                        print(reply[:500] + (\"...\" if len(reply) > 500 else \"\"))\n",
    "                        print(\"-\" * 40)\n",
    "                    \n",
    "                    # æ˜¾ç¤ºtokenä½¿ç”¨æƒ…å†µ\n",
    "                    if \"usage\" in result:\n",
    "                        usage = result[\"usage\"]\n",
    "                        print(f\"\\nğŸ“Š Tokenä½¿ç”¨:\")\n",
    "                        print(f\"   è¾“å…¥token: {usage.get('prompt_tokens', 'N/A')}\")\n",
    "                        print(f\"   è¾“å‡ºtoken: {usage.get('completion_tokens', 'N/A')}\")\n",
    "                        print(f\"   æ€»token: {usage.get('total_tokens', 'N/A')}\")\n",
    "                    \n",
    "                    return True\n",
    "                    \n",
    "                elif response.status_code == 404:\n",
    "                    print(f\"âŒ æ¨¡å‹ '{self.model}' ä¸å­˜åœ¨\")\n",
    "                    print(\"   è¯·ä½¿ç”¨ 'ollama pull' ä¸‹è½½æ¨¡å‹\")\n",
    "                    return False\n",
    "                else:\n",
    "                    print(f\"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}\")\n",
    "                    print(f\"   å“åº”: {response.text[:200]}\")\n",
    "                    \n",
    "            except requests.exceptions.Timeout:\n",
    "                print(f\"â° è¯·æ±‚è¶…æ—¶ï¼Œå°è¯•é‡è¯•...\")\n",
    "                time.sleep(1)\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ è¯·æ±‚å¼‚å¸¸: {str(e)}\")\n",
    "                time.sleep(1)\n",
    "        \n",
    "        print(f\"âš ï¸  æ‰€æœ‰ {self.max_retries} æ¬¡å°è¯•éƒ½å¤±è´¥\")\n",
    "        return False\n",
    "    \n",
    "    def test_streaming(self, prompt=\"Tell me a short joke\", max_tokens=100):\n",
    "        \"\"\"æµ‹è¯•æµå¼è¾“å‡º\"\"\"\n",
    "        print(f\"\\nğŸŒŠ æµ‹è¯•æµå¼è¾“å‡º\")\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        \n",
    "        data = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": messages,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0.7,\n",
    "            \"stream\": True\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            print(\"   å¼€å§‹æ¥æ”¶æµå¼å“åº”...\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/chat/completions\",\n",
    "                headers=self.headers,\n",
    "                json=data,\n",
    "                stream=True,\n",
    "                timeout=60,\n",
    "                verify=self.verify_ssl\n",
    "            )\n",
    "            \n",
    "            full_response = \"\"\n",
    "            if response.status_code == 200:\n",
    "                for line in response.iter_lines():\n",
    "                    if line:\n",
    "                        line_str = line.decode('utf-8')\n",
    "                        if line_str.startswith('data: '):\n",
    "                            data_str = line_str[6:]\n",
    "                            if data_str.strip() == '[DONE]':\n",
    "                                break\n",
    "                            \n",
    "                            try:\n",
    "                                chunk = json.loads(data_str)\n",
    "                                if \"choices\" in chunk and len(chunk[\"choices\"]) > 0:\n",
    "                                    delta = chunk[\"choices\"][0].get(\"delta\", {})\n",
    "                                    content = delta.get(\"content\", \"\")\n",
    "                                    if content:\n",
    "                                        print(content, end='', flush=True)\n",
    "                                        full_response += content\n",
    "                            except json.JSONDecodeError:\n",
    "                                continue\n",
    "                \n",
    "                print(f\"\\n\" + \"-\" * 40)\n",
    "                print(f\"âœ… æµå¼è¾“å‡ºå®Œæˆï¼Œæ€»é•¿åº¦: {len(full_response)} å­—ç¬¦\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"âŒ æµå¼è¯·æ±‚å¤±è´¥: {response.status_code}\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æµå¼è¯·æ±‚å¼‚å¸¸: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def test_generation(self, prompt=\"Once upon a time\", max_tokens=50):\n",
    "        \"\"\"æµ‹è¯•æ–‡æœ¬ç”Ÿæˆï¼ˆéèŠå¤©æ ¼å¼ï¼‰\"\"\"\n",
    "        print(f\"\\nğŸ“ æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ\")\n",
    "        \n",
    "        data = {\n",
    "            \"model\": self.model,\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0.7,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/completions\",\n",
    "                headers=self.headers,\n",
    "                json=data,\n",
    "                timeout=30,\n",
    "                verify=self.verify_ssl\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                if \"choices\" in result and len(result[\"choices\"]) > 0:\n",
    "                    text = result[\"choices\"][0].get(\"text\", \"\")\n",
    "                    print(f\"âœ… æ–‡æœ¬ç”ŸæˆæˆåŠŸ:\")\n",
    "                    print(\"-\" * 40)\n",
    "                    print(prompt + text)\n",
    "                    print(\"-\" * 40)\n",
    "                    return True\n",
    "            else:\n",
    "                print(f\"âŒ æ–‡æœ¬ç”Ÿæˆå¤±è´¥: {response.status_code}\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æ–‡æœ¬ç”Ÿæˆå¼‚å¸¸: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def run_all_tests(self):\n",
    "        \"\"\"è¿è¡Œæ‰€æœ‰æµ‹è¯•\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"Ollama æœ¬åœ°æ¨¡å‹æµ‹è¯•\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # 1. æ£€æŸ¥OllamaæœåŠ¡\n",
    "        print(\"\\n1. ğŸš€ æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€...\")\n",
    "        if not self.check_ollama_status():\n",
    "            print(\"âŒ æµ‹è¯•ç»ˆæ­¢: OllamaæœåŠ¡æœªè¿è¡Œ\")\n",
    "            return False\n",
    "        \n",
    "        # 2. æµ‹è¯•OpenAIå…¼å®¹API\n",
    "        print(\"\\n2. ğŸ”Œ æµ‹è¯•OpenAIå…¼å®¹API...\")\n",
    "        if not self.test_openai_compatible_api():\n",
    "            print(\"âš ï¸  OpenAIå…¼å®¹APIä¸å¯ç”¨ï¼Œå°è¯•ç›´æ¥æµ‹è¯•æ¨¡å‹...\")\n",
    "        \n",
    "        # 3. æµ‹è¯•ç®€å•å¯¹è¯\n",
    "        print(\"\\n3. ğŸ’¬ æµ‹è¯•ç®€å•å¯¹è¯...\")\n",
    "        self.test_chat_completion(\n",
    "            prompt=\"ç”¨ä¸­æ–‡ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±\",\n",
    "            max_tokens=150\n",
    "        )\n",
    "        \n",
    "        # 4. æµ‹è¯•æ¨ç†èƒ½åŠ›\n",
    "        print(\"\\n4. ğŸ§® æµ‹è¯•æ¨ç†èƒ½åŠ›...\")\n",
    "        self.test_chat_completion(\n",
    "            prompt=\"å¦‚æœæˆ‘æœ‰3ä¸ªè‹¹æœï¼Œåƒæ‰1ä¸ªï¼Œåˆä¹°äº†5ä¸ªï¼Œç°åœ¨æœ‰å¤šå°‘ä¸ªè‹¹æœï¼Ÿ\",\n",
    "            max_tokens=100\n",
    "        )\n",
    "        \n",
    "        # 5. æµ‹è¯•æµå¼è¾“å‡º\n",
    "        print(\"\\n5. ğŸŒŠ æµ‹è¯•æµå¼è¾“å‡º...\")\n",
    "        self.test_streaming(\n",
    "            prompt=\"ç”¨ä¸‰å¥è¯æè¿°å¤å¤©çš„ç¾å¥½\",\n",
    "            max_tokens=80\n",
    "        )\n",
    "        \n",
    "        # 6. æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ\n",
    "        print(\"\\n6. ğŸ“ æµ‹è¯•æ–‡æœ¬ç”Ÿæˆæ¥å£...\")\n",
    "        self.test_generation(\n",
    "            prompt=\"äººå·¥æ™ºèƒ½çš„æœªæ¥æ˜¯\",\n",
    "            max_tokens=50\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!\")\n",
    "        print(\"=\" * 60)\n",
    "        return True\n",
    "\n",
    "def main():\n",
    "    # é…ç½®\n",
    "    config = {\n",
    "        \"base_url\": \"http://localhost:11434/v1\",\n",
    "        \"model\": \"qwen3:0.6b \",\n",
    "        \"api_key\": \"ollama\",\n",
    "        \"max_retries\": 3,\n",
    "        \"verify_ssl\": False\n",
    "    }\n",
    "    \n",
    "    # åˆ›å»ºæµ‹è¯•å™¨\n",
    "    tester = OllamaTester(config)\n",
    "    \n",
    "    # è¿è¡Œæµ‹è¯•\n",
    "    try:\n",
    "        tester.run_all_tests()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†requests\n",
    "    try:\n",
    "        import requests\n",
    "    except ImportError:\n",
    "        print(\"âŒ éœ€è¦å®‰è£…requestsåº“\")\n",
    "        print(\"   è¯·è¿è¡Œ: pip install requests\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ebd2f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "æµ‹è¯•è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\næµ‹è¯•è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deer-flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
